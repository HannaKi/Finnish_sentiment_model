{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HannaKi/Finnish_sentiment_model/blob/main/Sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip --quiet -nc install transformers datasets"
      ],
      "metadata": {
        "id": "6CBzlgl8tbbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "wget https://korp.csc.fi/download/finsen/src/finsen-src.zip\n",
        "unzip finsen-src.zip"
      ],
      "metadata": {
        "id": "v3DAlpoGtqoW",
        "outputId": "48b1578c-8239-4983-ecb4-1c645c7e971b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  finsen-src.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "File ‘finsen-src.zip’ already there; not retrieving.\n",
            "\n",
            "replace finsen-src/finsen-src/FinnSentiment2020.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL\n",
            "(EOF or read error, treating as \"[N]one\" ...)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-7a8fa24e74c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nwget -nc https://korp.csc.fi/download/finsen/src/finsen-src.zip\\nunzip finsen-src.zip\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'\\nwget -nc https://korp.csc.fi/download/finsen/src/finsen-src.zip\\nunzip finsen-src.zip\\n'' returned non-zero exit status 1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "i-S0-NmVtUs8"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "import transformers\n",
        "import datasets\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from time import time\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fin_sent=pd.read_csv(\n",
        "    r'/content/finsen-src/finsen-src/FinnSentiment2020.tsv',\n",
        "    sep='\\t',\n",
        "    index_col=False, \n",
        "    header=None, \n",
        "    names=['A_sentiment','B_sentiment','C_sentiment','majority_value','derived_value','pre-annotated_smiley',\n",
        "    'pre-annotated_review', 'split', 'batch', 'idx', 'text'],\n",
        ")"
      ],
      "metadata": {
        "id": "UDoNIr8Et7Pm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping={1:'neg', 2:'neg', 3:'neut', 4:'pos', 5:'pos'}\n",
        "\n",
        "fin_sent['label']=fin_sent.derived_value.map(mapping)\n",
        "fin_sent.head()"
      ],
      "metadata": {
        "id": "Gwao44uDuymh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore the label balance\n",
        "sns.countplot(data=fin_sent, x='label'); # Not such a good balance...! "
      ],
      "metadata": {
        "id": "MmZSsODou0w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downsize the data and balance classes # TODO: how to deal better with class imbalance!\n",
        "pos=fin_sent[fin_sent.label=='pos']\n",
        "neg=fin_sent[fin_sent.label=='neg']\n",
        "neut=fin_sent[fin_sent.label=='neut']\n",
        "neg=neg[:len(pos)]\n",
        "neut=neut[:len(pos)]\n",
        "test=pd.concat([pos, neut, neg])\n",
        "\n",
        "sns.countplot(data=test, x='label'); "
      ],
      "metadata": {
        "id": "mC-JFL7Du5Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM baseline"
      ],
      "metadata": {
        "id": "iox1CMJsu9AU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y=fin_sent['label']\n",
        "X=fin_sent['text']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=123)\n",
        "\n",
        "vectorizer=TfidfVectorizer() # TODO: Better params?\n",
        "feature_matrix_train=vectorizer.fit_transform(X_train)\n",
        "feature_matrix_test=vectorizer.transform(X_test)\n",
        "\n",
        "cost=[]\n",
        "acc=[]\n",
        "t0 = time() # start timer\n",
        "for C in (0.001,0.01,0.1,1,10,100):\n",
        "    classifier=sklearn.svm.LinearSVC(C=C, max_iter=5000)\n",
        "    classifier.fit(feature_matrix_train, y_train)\n",
        "    # print(f\"C={C}\\t{classifier.score(feature_matrix_test, y_test):0.2f}\")\n",
        "    cost.append(C)\n",
        "    acc.append(classifier.score(feature_matrix_test, y_test))\n",
        "t1 = time() # end timer\n",
        "\n",
        "print(f\"Fitting and evaluating the model took {(t1-t0):0.2f} seconds.\")\n",
        "\n",
        "best_cost=cost[np.argmax(acc)]\n",
        "svm_classifier=sklearn.svm.LinearSVC(C=best_cost, max_iter=5000)\n",
        "svm_classifier.fit(feature_matrix_train, y_train)\n",
        "preds=svm_classifier.predict(feature_matrix_test)"
      ],
      "metadata": {
        "id": "5HtzBwAfu74P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns represent the predicted labels and the rows represent the real labels\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "labels=list(set(y_train)) # labels for the image, not for the data :)\n",
        "labels.sort()\n",
        "\n",
        "cf_mat=confusion_matrix(y_test, preds, labels=labels)\n",
        "\n",
        "def plot_cf_matrix(mat):\n",
        "  sns.heatmap(mat, annot=True, fmt=\"d\", xticklabels=labels, yticklabels=labels)#, annot_kws=m)\n",
        "  plt.title(\"Confusion matrix for test data\", fontsize = 16)\n",
        "  plt.ylabel(\"True class\", fontsize = 14)\n",
        "  plt.xlabel(\"Predicted class\", fontsize = 14)\n",
        "\n",
        "plot_cf_matrix(cf_mat)\n",
        "\n",
        "print(f\"Model mean accuracy {svm_classifier.score(feature_matrix_test, y_test)}\") # TODO: precision, recall, F1"
      ],
      "metadata": {
        "id": "Ez8gTNCXvBHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT"
      ],
      "metadata": {
        "id": "FVzBxfL9vR-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME ='TurkuNLP/bert-base-finnish-cased-v1' # name from Hugging Face repository\n",
        "BATCH_SIZE = 64 # Not optimized.\n",
        "LEARNING_RATE = 2e-5 # Super important! Try this: 1e-5\n",
        "TRAIN_EPOCHS = 2"
      ],
      "metadata": {
        "id": "lwLc9sx0vTxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained(MODEL_NAME) "
      ],
      "metadata": {
        "id": "yE9_xvvbvVR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stratifying by column is only supported for ClassLabel column so make it!\n",
        "\n",
        "class_names = ['pos', 'neut', 'neg']\n",
        "dataset = datasets.Dataset.from_pandas(\n",
        "  fin_sent[['text', 'label']], \n",
        "  #preserve_index=False, \n",
        "  features=datasets.Features( # provide the feature classes to make sure you get what you need\n",
        "    {'text': datasets.Value('string'),\n",
        "     'label': datasets.ClassLabel(names=class_names) # values 0 and 1, label names accept and reject\n",
        "     }\n",
        "     )\n",
        ")"
      ],
      "metadata": {
        "id": "TOi-vwBYvYr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# is the data ok? take a look:\n",
        "for i in range(5):\n",
        "  print('Label:',dataset['label'][i], '\\nFeedback:', dataset['text'][i])\n",
        "  print()"
      ],
      "metadata": {
        "id": "ij05kTwgva2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data first in two parts. Note that this method shuffles the data and stratifies.\n",
        "\n",
        "# Returns a dictionary (datasets.DatsetDict) with two random train and test subsets (train and test Dataset splits).\n",
        "train_test = dataset.train_test_split(test_size=0.15, stratify_by_column='label') # 0.3\n",
        "\n",
        "# Split the test data again to gain two datasets: one for development and one for testing\n",
        "test_data = train_test['test'].train_test_split(test_size=0.5) # 0.2\n",
        "\n",
        "# Store the data in a DatasetDict (so we can use a map function later to tokenize the data)\n",
        "dataset = datasets.DatasetDict({\n",
        "    'train': train_test['train'],\n",
        "    'development': test_data['test'],\n",
        "    'test': test_data['train']})\n",
        "\n",
        "print(dataset) # check the splits"
      ],
      "metadata": {
        "id": "-pzmnbnvvc8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# truncation = True: The tokenizer limits the input size to 512 tokens. See QA-code for longer input if needed!\n",
        "\n",
        "def encode_dataset(d):\n",
        "  return tokenizer(d['text'], max_length=512, truncation=True)#,return_tensors='pt') \n",
        "\n",
        "\n",
        "encoded_dataset = dataset.map(encode_dataset) #tokenize all of the data with map-method"
      ],
      "metadata": {
        "id": "Pl5cZmPovfOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_dataset=encoded_dataset.remove_columns('text')\n",
        "encoded_dataset"
      ],
      "metadata": {
        "id": "wBEIdAxCvg5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    y_pred = pred.predictions.argmax(axis=1) \n",
        "    # we get the probability distribution out and the highest is selected with argmax\n",
        "    y_true = pred.label_ids\n",
        "    TP = len([a and b for a, b in zip(y_pred, y_true) if a == 1 and b == 1])\n",
        "    TN = len([a and b for a, b in zip(y_pred, y_true) if a == 0 and b == 0])\n",
        "    FN = len([a and b for a, b in zip(y_pred, y_true) if a == 0 and b == 1])\n",
        "    FP = len([a and b for a, b in zip(y_pred, y_true) if a == 1 and b == 0])\n",
        "\n",
        "    ACC = (TP+TN)/(TP+FP+FN+TN) # Overall accuracy\n",
        "    PRE = TP/(TP+FP) # Precision: share of relevant items\n",
        "    REC = TP/(TP+FN) # Recall: proportion of relevant items found\n",
        "    F1 = (2*((PRE*REC)/(PRE+REC))) # Balance between precision and recall\n",
        "    return {'accuracy': ACC,\n",
        "            'precision': PRE, \n",
        "            'recall': REC,\n",
        "            'F1-score':F1\n",
        "            }"
      ],
      "metadata": {
        "id": "YQ3v46y3vhsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(set(df['label'])))\n",
        "\n",
        "# Training arguments how to train, when to save the model weights\n",
        "train_args = transformers.TrainingArguments(\n",
        "    '/Users/kittiha/Analyysit/Teksti_analytiikkaa/BERT_model',\n",
        "    save_strategy='epoch',\n",
        "    evaluation_strategy='epoch', # look at the performence measures (accuracy, precision, recall, F1-score, what ever defined) after each epoch\n",
        "    logging_strategy='epoch',\n",
        "    learning_rate=LEARNING_RATE, \n",
        "    per_device_train_batch_size=BATCH_SIZE, \n",
        "    num_train_epochs=TRAIN_EPOCHS, \n",
        "    metric_for_best_model='F1-score', # use with Early Stopping callback\n",
        "    load_best_model_at_end=True,      # restore the best model when training finishes\n",
        "    weight_decay=0.01                # strength of weight decay\n",
        ")\n",
        "\n",
        "early_stopping = transformers.EarlyStoppingCallback(early_stopping_patience = 2)"
      ],
      "metadata": {
        "id": "hA1QgtZyvjo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model,\n",
        "    train_args,\n",
        "    train_dataset = encoded_dataset['train'],\n",
        "    eval_dataset = encoded_dataset['development'],\n",
        "    tokenizer = tokenizer,\n",
        "    compute_metrics = compute_metrics,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "OcWVdFTCvm8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train() \n",
        "ml_metrics = trainer.evaluate() # check, that the best model was reloaded\n",
        "print(ml_metrics)"
      ],
      "metadata": {
        "id": "2zZ5yPGpvo-h"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}